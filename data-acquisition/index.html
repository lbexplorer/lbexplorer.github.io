<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>数据获取与清洗 | 基于情感分析和LDA主题构建的影评知识图谱模型</title><meta name="author" content="Liu Bo"><meta name="copyright" content="Liu Bo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1. 数据来源在本项目中，我们的数据来源于多个电影评分网站，针对这些网站的数据可靠性分析如下所示 B站 数据质量和可靠性分析：  B站是一个视频分享平台，用户数量众多，因此收集到的影评数据较为丰富。 由于用户生成内容，数据质量可能有所不同，需要进行一定程度的筛选和清洗。 部分用户可能存在水军等不真实评论，对数据的可信度产生影响，需要谨慎处理。    腾讯视频 数据质量和可靠性分析：  腾讯视频作为"><meta property="og:type" content="website"><meta property="og:title" content="数据获取与清洗"><meta property="og:url" content="http://example.com/data-acquisition/index.html"><meta property="og:site_name" content="基于情感分析和LDA主题构建的影评知识图谱模型"><meta property="og:description" content="1. 数据来源在本项目中，我们的数据来源于多个电影评分网站，针对这些网站的数据可靠性分析如下所示 B站 数据质量和可靠性分析：  B站是一个视频分享平台，用户数量众多，因此收集到的影评数据较为丰富。 由于用户生成内容，数据质量可能有所不同，需要进行一定程度的筛选和清洗。 部分用户可能存在水军等不真实评论，对数据的可信度产生影响，需要谨慎处理。    腾讯视频 数据质量和可靠性分析：  腾讯视频作为"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><meta property="article:published_time" content="2024-04-21T08:39:13.000Z"><meta property="article:modified_time" content="2024-05-04T09:50:44.598Z"><meta property="article:author" content="Liu Bo"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/data-acquisition/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:void 0,translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"数据获取与清洗",isPost:!1,isHome:!1,isHighlightShrink:!0,isToc:!0,postUpdate:"2024-05-04 17:50:44"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside")),/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body;e.style.overflow="hidden",d.classList.remove("loaded"),window.addEventListener("load",(()=>{e.style.overflow="",d.classList.add("loaded")}))})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/project-introduction/"><i class="fa-fw fas fa-info-circle"></i><span> 项目简介</span></a></div><div class="menus_item"><a class="site-page" href="/data-acquisition/"><i class="fa-fw fas fa-chart-bar"></i><span> 數據获取与清洗</span></a></div><div class="menus_item"><a class="site-page" href="/data-analysis/"><i class="fa-fw fas fa-chart-line"></i><span> 數據处理与分析</span></a></div><div class="menus_item"><a class="site-page" href="/data-result/"><i class="fa-fw fas fa-link"></i><span> 项目总结</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-home-page" id="page-header" style="background-image:url('/img/bg.png')"><nav id="nav"><span id="blog-info"><a href="/" title="基于情感分析和LDA主题构建的影评知识图谱模型"><span class="site-name">基于情感分析和LDA主题构建的影评知识图谱模型</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/project-introduction/"><i class="fa-fw fas fa-info-circle"></i><span> 项目简介</span></a></div><div class="menus_item"><a class="site-page" href="/data-acquisition/"><i class="fa-fw fas fa-chart-bar"></i><span> 數據获取与清洗</span></a></div><div class="menus_item"><a class="site-page" href="/data-analysis/"><i class="fa-fw fas fa-chart-line"></i><span> 數據处理与分析</span></a></div><div class="menus_item"><a class="site-page" href="/data-result/"><i class="fa-fw fas fa-link"></i><span> 项目总结</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="page-site-info"><h1 id="site-title">数据获取与清洗</h1></div></header><main class="layout" id="content-inner"><div id="page"><div id="article-container"><h1 id="1-数据来源"><a href="#1-数据来源" class="headerlink" title="1. 数据来源"></a>1. 数据来源</h1><p>在本项目中，我们的数据来源于多个电影评分网站，针对这些网站的数据可靠性分析如下所示</p><h2 id="B站"><a href="#B站" class="headerlink" title="B站"></a>B站</h2><ul><li><strong>数据质量和可靠性分析：</strong><ul><li>B站是一个视频分享平台，用户数量众多，因此收集到的影评数据较为丰富。</li><li>由于用户生成内容，数据质量可能有所不同，需要进行一定程度的筛选和清洗。</li><li>部分用户可能存在水军等不真实评论，对数据的可信度产生影响，需要谨慎处理。</li></ul></li></ul><h2 id="腾讯视频"><a href="#腾讯视频" class="headerlink" title="腾讯视频"></a>腾讯视频</h2><ul><li><strong>数据质量和可靠性分析：</strong><ul><li>腾讯视频作为中国领先的视频网站之一，具有大量用户群体和丰富的视频内容。</li><li>平台管理较为严格，对影评内容进行一定程度的审核和过滤，提高了数据的质量和可信度。</li><li>数据相对可靠，但仍需注意部分用户可能存在盲目追随或者水军行为，需要加以识别和处理。</li></ul></li></ul><h2 id="豆瓣"><a href="#豆瓣" class="headerlink" title="豆瓣"></a>豆瓣</h2><ul><li><strong>数据质量和可靠性分析：</strong><ul><li>豆瓣是一个专业的电影评分和影评平台，用户活跃度高，对影片品质有较高的要求。</li><li>平台提供了丰富的影评数据，其中大部分用户具有较高的电影素养，对数据质量有所保障。</li><li>数据质量较高，可靠性强，但仍需注意个别用户可能存在主观偏见或者恶意评论，需要进行筛选和排除。</li></ul></li></ul><h2 id="猫眼"><a href="#猫眼" class="headerlink" title="猫眼"></a>猫眼</h2><ul><li><strong>数据质量和可靠性分析：</strong><ul><li>猫眼是中国领先的电影信息与电影票务在线交易平台，用户对电影的评分和评论较为直观。</li><li>平台提供了较为真实和可靠的影评数据，用户对影片的评价较为客观，数据质量相对较高。</li><li>数据相对可靠，但仍需注意平台可能存在推广和宣传导向，需要进行分析和甄别。</li></ul></li></ul><h1 id="2-数据获取方法"><a href="#2-数据获取方法" class="headerlink" title="2.数据获取方法"></a>2.数据获取方法</h1><p>在本项目中，我们使用 Python 编写的网络爬虫来从多个电影评分网站抓取数据。这些网站包括 b站, 豆瓣电影，腾讯视频，猫眼等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> xml.etree.ElementTree <span class="keyword">import</span> fromstring</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fetch_bilibili_danmus</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 发送网络请求</span></span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        response.raise_for_status()  <span class="comment"># 如果请求失败，则抛出异常</span></span><br><span class="line">        xml_content = response.content</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解析XML数据</span></span><br><span class="line">        xml_root = fromstring(xml_content)</span><br><span class="line">        danmus = []</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> xml_root.findall(<span class="string">&#x27;d&#x27;</span>):</span><br><span class="line">            danmu_text = d.text</span><br><span class="line">            danmus.append(danmu_text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> danmus</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;An error occurred: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    url = <span class="string">&#x27;https://comment.bilibili.com/1436594258.xml&#x27;</span> <span class="comment">#地址+cid 需要修改</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取弹幕数据</span></span><br><span class="line">    danmus = fetch_bilibili_danmus(url)</span><br><span class="line">    <span class="keyword">if</span> danmus:</span><br><span class="line">        <span class="comment"># 将弹幕数据转换成DataFrame</span></span><br><span class="line">        danmu_df = pd.DataFrame(danmus, columns=[<span class="string">&#x27;弹幕内容&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 存储到本地CSV文件</span></span><br><span class="line">        danmu_df.to_csv(<span class="string">&#x27;bilibili_danmus.csv&#x27;</span>, encoding=<span class="string">&#x27;utf_8_sig&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;弹幕数据已保存到文件: bilibili_danmus.csv&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未能获取弹幕数据，可能由于网络请求失败。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h1 id="3-数据清洗"><a href="#3-数据清洗" class="headerlink" title="3.数据清洗"></a>3.数据清洗</h1><p>针对影评文本信息，数据清洗是非常重要的。为了提升分析效果，对不同问题采取不同的预处理方法是必要的：</p><ol><li><p><strong>去除特殊字符和标点符号</strong>：<br>特殊字符和标点符号往往不包含有效信息，它们不仅影响处理时间，还可能降低整体数据质量。因此，可以删除评论中的特殊字符、标点符号等非文本信息，以净化文本内容。</p></li><li><p><strong>空行、空字符串及无意义数据</strong>：<br>空白行、空字符串以及无意义的数据没有任何有效信息，将它们直接纳入语义分析可能降低整体质量，甚至导致一些消极后果。因此，过滤掉这些非结构化信息并删除空信息及无意义评论信息，可以提高文本数据的语义信息含量。</p></li><li><p><strong>带有 Emoji 等特殊符号的评论数据</strong>：<br>虽然带有 Emoji 等特殊符号的评论数据能反映用户的情感，但它们会干扰分词过程，并在某些情况下影响程序的运行。因此，需对这些数据进行特殊处理，如将 Emoji 和表情符号转换为相应的描述或标记，以便在后续分析中更好地处理。</p></li><li><p><strong>繁体字、昵称、别名等可替代数据</strong>：<br>繁体字、昵称、别名等尽管有明确意义，但繁体和简体字在计算机编码中被视为不同字符，可能导致知识抽取时出现同义异构问题。因此，需要对这些数据进行繁简转换，并将流行的昵称、别名和简写替换为原始信息或标准名称，以降低语义分析的复杂度。<br>数据清洗的部分代码如下：</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建停用词list</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_stopwords_list</span>(<span class="params">filepath</span>):</span><br><span class="line">    stopwords = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(filepath, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>).readlines()]</span><br><span class="line">    <span class="keyword">return</span> stopwords</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对句子进行分词和去除停用词</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_sentence</span>(<span class="params">sentence, stopwords</span>):</span><br><span class="line">    sentence_seged = jieba.cut(sentence.strip())</span><br><span class="line">    outstr = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sentence_seged:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">&#x27;\t&#x27;</span>:</span><br><span class="line">                outstr += word</span><br><span class="line">                outstr += <span class="string">&quot;,&quot;</span></span><br><span class="line">    <span class="keyword">return</span> outstr</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对文本进行预处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_text</span>(<span class="params">input_file, output_file, stopwords_path</span>):</span><br><span class="line">    stopwords = create_stopwords_list(stopwords_path)</span><br><span class="line">    data = pd.read_csv(input_file, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(output_file, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f_out:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> data[<span class="string">&#x27;cleaned_content&#x27;</span>]: <span class="comment">#需要使用清洗后的数据的列</span></span><br><span class="line">            line = re.sub(<span class="string">&quot;[A-Za-z0-9]|亿|票房|电影|破|微博|视频|展开|全文|这篇|影评|有剧|透|\n|&quot;</span>, <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">                          <span class="built_in">str</span>(line)).strip()</span><br><span class="line">            <span class="keyword">for</span> ch <span class="keyword">in</span> <span class="string">&quot;☆♂※↓‘’“”〝〞（）〈〉‹›﹛﹜『』〖〗［］〔〕&#123;&#125;「」【】。，、：∶；?ˆˇ﹕︰﹔﹖﹑·¨…;.¸！´？！～—ˉ｜‖＂〃｀@﹫¡¿﹋﹏﹌︴々﹟#﹩$﹠&amp;amp;﹪%*﹡﹢﹦﹤‐￣―¯﹨ˆ˜﹍﹎+=&amp;lt;­­＿_-\ˇ~﹉﹊aa︵︷︿︹︽_﹁﹁﹃︻︶︸﹀︺︾ˉ﹂，。、：？！（）【】《》,.!?&lt;&gt;&#123;&#125;[]|\n/…—-_ ;:：；\&quot;”“~*#$&amp;@\&#x27;()&quot;</span>:</span><br><span class="line">                line = line.replace(ch, <span class="string">&quot;&quot;</span>)</span><br><span class="line">            line_seg = tokenize_sentence(line, stopwords)</span><br><span class="line">            <span class="keyword">if</span> line_seg:  <span class="comment"># 如果处理后的文本不为空，则写入文件</span></span><br><span class="line">                f_out.write(line_seg.rstrip(<span class="string">&#x27;,&#x27;</span>) + <span class="string">&#x27;\n&#x27;</span>)  <span class="comment"># 移除末尾逗号并写入文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 输入文件路径-可修改</span></span><br><span class="line">    input_file = <span class="string">&#x27;data/bilibili_danmus2_cleaned.csv&#x27;</span></span><br><span class="line">    <span class="comment"># 输出文件路径-可修改</span></span><br><span class="line">    output_file = <span class="string">&#x27;data/bilibili_danmus2_tokenized.csv&#x27;</span></span><br><span class="line">    <span class="comment"># 停用词文件路径</span></span><br><span class="line">    stopwords_path = <span class="string">&#x27;data/stopword.txt&#x27;</span></span><br><span class="line">    <span class="comment">#此处采用的是相对路径，仅需要在data目录下存放数据即可。</span></span><br><span class="line">    <span class="comment"># 执行预处理</span></span><br><span class="line">    preprocess_text(input_file, output_file, stopwords_path)</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="4-数据展示"><a href="#4-数据展示" class="headerlink" title="4.数据展示"></a>4.数据展示</h1><p>在我们的电影分析项目中，成功收集了来自多个平台的影评数据，总计超过50,000条。这些数据涵盖了广泛的观众意见和评论，为我们提供了一个宝贵的资源库来深入理解不同观众对电影的感受和评价。为了有效地利用这些数据，我们首先对其进行了细致的统计性分析，旨在揭示观众的整体倾向、喜好的电影类型、以及对特定电影元素的评价等关键信息。</p><h2 id="飞驰人生系列电影影评各平台获取"><a href="#飞驰人生系列电影影评各平台获取" class="headerlink" title="飞驰人生系列电影影评各平台获取"></a>飞驰人生系列电影影评各平台获取</h2><img src="https://pic.imgdb.cn/item/6632461e0ea9cb14039246a3.png" alt="飞驰人生影评比例图" style="width:60%"><h2 id="词云图"><a href="#词云图" class="headerlink" title="词云图"></a>词云图</h2><p>对影评进行分词处理之后，统计影评分词的频率，制作出如下词云图：</p><ul><li><strong>飞驰人生1词云图</strong><img src="https://pic.imgdb.cn/item/6632447e0ea9cb14038ee746.jpg" alt="飞驰人生1词云图" style="width:40%"> 《飞驰人生1》电影评论中，占比较大的词语有“韩寒”、“电影”、“导演”、“沈腾”等与当前人气高的演职人员及角色相关的词的出现，可以体现出观众对演职人员及导演拍摄影片的较高关注度；也有“赛车”、“搞笑”、“笑点”、“喜剧”、“热血”、“喜欢”、“段子”等与电影类型观众情感相关的词出现，这些词能更好的反映了观众的情感，反映了观众对该电影的喜欢。</li><li><strong>飞驰人生2词云图</strong><img src="https://pic.imgdb.cn/item/6632447e0ea9cb14038ee7b2.png" alt="飞驰人生2词云图" style="width:40%"> 《飞驰人生2》电影评论中，占比较大的词语也出现了“韩寒”、“电影”、“沈腾”等与当前人气高的演职人员及角色相关的词，可以体现出观众对演职人员及导演拍摄影片的热情不减反增；也出现了有关电影类型观众情感相关的词，如“剧情”、“赛车”、“故事”、“喜欢”、“热血”。除此之外，出现了新的词语，如“第一部”、“第二部”、“这部”等体现系列电影评论特点的词汇，许多被用来与当前所评论的电影作比较，也反映了观众十分期望第二部的剧情与电影质量。</li></ul><h2 id="星级分布图"><a href="#星级分布图" class="headerlink" title="星级分布图"></a>星级分布图</h2><p>为了能够体现两部电影的在观众中的受欢迎程度，选择两部电影上映后的3个月之内，同一平台的所有热门影评数据制作出如下星级分布图</p><ul><li><p><strong>飞驰人生1电影豆瓣平台影评星级分布图</strong>：</p><img src="https://pic.imgdb.cn/item/6632655e0ea9cb1403dcd050.png" alt="飞驰人生1电影豆瓣平台影评星级分布图" style="width:60%"></li><li><p><strong>飞驰人生2电影豆瓣平台影评星级分布图</strong>：</p><img src="https://pic.imgdb.cn/item/6632655e0ea9cb1403dcd0d3.png" alt="飞驰人生2电影豆瓣平台影评星级分布图" style="width:60%"></li></ul><p>星级分布图显示，大多数评论为5星，这是最高评级，表明观众普遍对《飞驰人生2》给予极高的评价。这种集中在高星级的分布反映了电影在目标观众中的成功和广泛的接受度。评论的分布呈现极化趋势，即大多数观众倾向于给出非常高的评价，而很少有人给出低评价。这种极化可能指示电影具有较强的受众分化，吸引了一群非常热情的支持者。高比例的5星评价表明电影在市场上具有很好的接受度，可能对相似类型的电影制作和营销策略产生积极影响。</p><h2 id="时间分布图"><a href="#时间分布图" class="headerlink" title="时间分布图"></a>时间分布图</h2><img src="https://pic.imgdb.cn/item/6636014a0ea9cb1403b47659.png" alt="飞驰人生2电影豆瓣平台影评星级分布图" style="width:60%"> 图中明显显示了某些小时段评论数量显著增多。这通常对应于日常生活中的闲暇时间，例如晚上下班后的几个小时。这种模式表明大部分观众可能在这些时段观看电影并留下评论。而对于电影制片方或营销团队而言，这种时段分析可以指导他们在何时发布宣传内容或互动帖子，以最大化观众的参与度和反馈。同时如果某个时间段有突发的评论增加，这可能与特定事件或活动相关（例如电影首映或特别放映），这种信息对于评估市场反应和观众兴趣非常有用。</div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90"><span class="toc-number">1.</span> <span class="toc-text">1. 数据来源</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#B%E7%AB%99"><span class="toc-number">1.1.</span> <span class="toc-text">B站</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%85%BE%E8%AE%AF%E8%A7%86%E9%A2%91"><span class="toc-number">1.2.</span> <span class="toc-text">腾讯视频</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B1%86%E7%93%A3"><span class="toc-number">1.3.</span> <span class="toc-text">豆瓣</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8C%AB%E7%9C%BC"><span class="toc-number">1.4.</span> <span class="toc-text">猫眼</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E6%96%B9%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">2.数据获取方法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97"><span class="toc-number">3.</span> <span class="toc-text">3.数据清洗</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E6%95%B0%E6%8D%AE%E5%B1%95%E7%A4%BA"><span class="toc-number">4.</span> <span class="toc-text">4.数据展示</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A3%9E%E9%A9%B0%E4%BA%BA%E7%94%9F%E7%B3%BB%E5%88%97%E7%94%B5%E5%BD%B1%E5%BD%B1%E8%AF%84%E5%90%84%E5%B9%B3%E5%8F%B0%E8%8E%B7%E5%8F%96"><span class="toc-number">4.1.</span> <span class="toc-text">飞驰人生系列电影影评各平台获取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%8D%E4%BA%91%E5%9B%BE"><span class="toc-number">4.2.</span> <span class="toc-text">词云图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%98%9F%E7%BA%A7%E5%88%86%E5%B8%83%E5%9B%BE"><span class="toc-number">4.3.</span> <span class="toc-text">星级分布图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E5%88%86%E5%B8%83%E5%9B%BE"><span class="toc-number">4.4.</span> <span class="toc-text">时间分布图</span></a></li></ol></li></ol></div></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">1</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastpushdate="2024-05-05T05:31:07.392Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>